{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Indexing\n",
    "\n",
    "### Multiindex\n",
    "\n",
    "If you set an index to more than one columnn you are creating multi index or Hieararchical index. This makes asking questions based on indexes a lot more easier, and also opens the possibility of working with multidimensional data. \n",
    "\n",
    "We'll use the example sourced from [here](https://chrisalbon.com/python/pandas_hierarchical_data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
    "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
    "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
    "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
    "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_ind = df.set_index('regiment')\n",
    "df_1_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_ind.mean(level = 'regiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How about you want to get the mean scores, based on the company but not the regiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hierarchical index to be by regiment, and then by company\n",
    "df_2_ind = df.set_index(['regiment', 'company'])\n",
    "df_2_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "Having multiple indexes will give you an easy way to model more than two dimensional data with DataFrames. Remember DataFraemes are by default a two dimensional data structures. \n",
    "</p>\n",
    "<p>\n",
    "For the above example, you can imagine each regiment is a two-dimensional array giving details about the company, names and the scores, and they are stacked one below the other. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level='regiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level=['regiment','company'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen some simple aggregations on Pandas **`Series`** and **`DataFrame`** objects.\n",
    "\n",
    "Let us review a few aggregation functions that will help us in understanding the **Grouping**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll be using our college scorecard dataset in this tutorial.\n",
    "college_scorecard = pd.read_csv(\n",
    "    './data/college-scorecard-data-scrubbed.csv', \n",
    "    encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_averages = college_scorecard['sat_average']\n",
    "print('Mean: {}'.format(sat_averages.mean()))\n",
    "print('Max: {}'.format(sat_averages.max()))\n",
    "print('Min: {}'.format(sat_averages.min()))\n",
    "print('Median: {}'.format(sat_averages.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "Remember, that a series actually holds its values in a nested NumPy array (ndarray) object. Pandas simply has to apply these aggregations functions to that nested array.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of available `Series` and `DataFrame` aggregation methods from your textbook.\n",
    "\n",
    "| Aggregation Function      | Description    |      \n",
    "|---------------|---------------------|\n",
    "|count()        |Total number of items (not including NaN)|\n",
    "|first(), last()|First and last item  |\n",
    "|mean(), median()  |Mean and median   |\n",
    "|min(), max()   |Minimum and Maximum  |\n",
    "|std(), var()   |Standard deviation & variance |\n",
    "|mad()          |Mean absolute deviation |\n",
    "|prod()         |Product of all items         |\n",
    "|sum()          |Sum of all items           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `describe()` method\n",
    "The `describe()` method is available on both **`Series`** and **`DataFrame`** objects and outputs a variety of aggregations that are very useful in getting the general \"sense\" of a dataset.\n",
    "\n",
    "Take a look at the output for our **`sat_average`** series and **`college_scorecard`** dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_averages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweaking `describe()` behavior with `include` and `exclude` parameters.\n",
    "When used on a **`DataFrame`** object, the default behavior of the **`describe()`** method is to provide statistics on numeric columns only.\n",
    "\n",
    "Let's take a look at the **`dtypes`** attribute on our college_scorecard dataframe to see what columns this does/doesn't include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "The `dtype` attribute of `DataFrame` objects returns information on the datatype of each nested series/column.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all the places where it lists the datatype of a column as 'object'? These columns won't be reported on with **`describe()`** when using the default parameters.\n",
    "\n",
    "We can change this using either the **`include`** or the **`exclude`** parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the object datatype columns\n",
    "college_scorecard.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the numeric datatypes\n",
    "college_scorecard.describe(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things here to notice:\n",
    "1. The type of statistics returned changed when operating on **`object`** column types.\n",
    "2. I used NumPy datatypes in the specification of what to include and exclude.\n",
    "\n",
    "**The Statistics**  \n",
    "Object(esp. string based) columns cannot be summarized reasonably with many of numeric aggregations so Pandas gives an alternative set of aggregations which make more sense for this type of data.\n",
    "\n",
    "**NumPy Datatypes**  \n",
    "Remember that the values of each `Series` inside of a `DataFrame` are stored in a NumPy array. Therefore the elements in that NumPy array are described by NumPy datatypes.\n",
    "\n",
    "That is why we specify NumPy datatypes here to specifically include/exclude them for Pandas `describe` method.\n",
    "\n",
    "This is just another example of the tight integration between the two libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can specify **`include='all'`** to force Pandas\n",
    "# to evaluate all columns.  It will inject NaN where\n",
    "# a calculation cannot be done.\n",
    "college_scorecard.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will look at the sample dataset of the flight schedules data that is available on Kaggle [here](https://www.kaggle.com/usdot/flight-delays)\n",
    "\n",
    "This is only a sample of the original data. You will use the original data in your Group (no pun intended) Project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('./data/flight_sample.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `groupby()` Method\n",
    "\n",
    "So far, all the calculations that we've done on **`DataFrame`** objects have looked at the values of columns as a whole.\n",
    "\n",
    "The `groupby()` method allows you to move into deeper forms analysis by splitting up the rows of a dataset into groups by the values in specified row(s). You can think of this in some ways as putting rows into buckets for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying how to Split your Dataset into Groups\n",
    "Of course, before we can perform evaluations on groups, we have to create them from an existing dataframe. \n",
    "\n",
    "Let's explore how **`groupby()`** provides a variety of ways to split up your datasets. We'll explore some of these here, starting with the most simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Column Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline = flights.groupby(['AIRLINE'])\n",
    "flights_by_airline.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`groupby()`** method returns an type called **`DataFrameGroupBy`**. We will explore it in more depth shortly, but for now just know that it has an attribute called **`groups`** which provides a *`dict`* object with the **labels** of each group and the **corresponding index values** in the original dataframe that belong to that group.\n",
    "\n",
    "If you look above, you can see there is a group labelled 'AA' will index values [2,   19,   43,   55,   59,   64,   71,   74,   82,   92, ...].\n",
    "\n",
    "You can think of this as a record of all the groups that we will perform calculations on later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Column Grouping\n",
    "\n",
    "You can specify multiple columns if you wish to split your data up in multiple levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline_month = flights.groupby(['AIRLINE', 'MONTH'])\n",
    "flights_by_airline_month.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations after GroupBy\n",
    "\n",
    "For example, let us say you want to find out the average distance traveled by each airline, you can do that using the following aggregeate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_by_airline = flights.groupby(['AIRLINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline[['DISTANCE']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "##### Aggregation operations\n",
    "\n",
    "1. Describe only numerical values of flights dataset. \n",
    "2. Describe only the non-numerical values of the flights dataset. \n",
    "3. Describe all the columns of the flights dataset. \n",
    "\n",
    "\n",
    "##### GroupBY\n",
    "\n",
    "1. Extract only the flight details of the American Airlines (AA) \n",
    "2. What is the median monthly DISTANCE, TAXI_IN times and TAXI_OUT times? \n",
    "3. How about above summary statistics for United Airlines (UA)? \n",
    "4. Instead of doing this for each airline, what can you do so that you get all per airline per month summary statistics? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
